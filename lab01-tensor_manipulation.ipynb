{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "#1d array\n",
    "t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "#float형 텐서로 만들겠다.\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n",
      "tensor(0.) tensor(1.) tensor(6.)\n",
      "tensor([2., 3., 4.]) tensor([4., 5.])\n",
      "tensor([0., 1.]) tensor([3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim()) #rank ->몇 개의 차원이 있니\n",
    "print(t.shape) #shape\n",
    "print(t.size()) #shape와 같음\n",
    "print(t[0], t[1], t[-1])\n",
    "print(t[2:5], t[4:-1])\n",
    "print(t[:2], t[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "#2d array\n",
    "t = torch.FloatTensor([[1., 2., 3.],\n",
    "                      [4., 5., 6.],\n",
    "                      [7., 8., 9.],\n",
    "                      [10., 11., 12.]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n",
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim())\n",
    "print(t.size())\n",
    "print(t[:, 1]) #두번째 것만 가져와라\n",
    "print(t[:, 1].size())\n",
    "print(t[:, :-1]) #맨마지막을 제외한 것을 가져와"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 5.])\n"
     ]
    }
   ],
   "source": [
    "#broadcasting\n",
    "#두 텐서 간 크기가 같아야 한다 등 규칙이 있지만\n",
    "#다른 크기의 행렬과 텐서를 연산할 수 있음.\n",
    "#broadcasting이 이를 가능하게 해줌.\n",
    "m1 = torch.FloatTensor([3, 3])\n",
    "m2 = torch.FloatTensor([2, 2])\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "#vector + scalar\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([3]) # 3-> [[3,3]]으로 자동으로 바꿔줌\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "#텐서 간 연산에도 가능\n",
    "# 2x1 vector + 1x2 vector\n",
    "m1 = torch.FloatTensor([[1,2]]) #(1,2) -> (2,2) 따라서 [[1,2],[1,2]]\n",
    "m2 = torch.FloatTensor([[3], [4]]) #(2,1) ->(2,2) 따라서 [[3,4]],[[3,4]]\n",
    "print(m1 + m2)\n",
    "\n",
    "'''\n",
    "브로드캐스팅은 자동으로 되기 때문에 주의해야 함!\n",
    "실수를 해서 다른 사이즈가 계산되면 원래의 계획과 달라진다!\n",
    "프로그램이 어디서 잘못됐는가!를 모름\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of matrix1:  torch.Size([2, 2])\n",
      "shape of matrix2:  torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "#matrix multiplication\n",
    "\n",
    "#일반적인 매트릭스 곱셈\n",
    "m1 = torch.FloatTensor([[1,2], [3,4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('shape of matrix1: ', m1.shape)\n",
    "print('shape of matrix2: ', m2.shape)\n",
    "print(m1.matmul(m2)) #매트릭스곱\n",
    "print(m1.mul(m2)) #m2가 [1,1],[2,2]로 늘어남, 각각 1번째끼리 곱, 2번째끼리곱,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n",
      "Can only calculate the mean of floating types. Got Long instead.\n"
     ]
    }
   ],
   "source": [
    "#평균을 구하는 방법\n",
    "\n",
    "t = torch.FloatTensor([1,2])\n",
    "print(t.mean())\n",
    "\n",
    "t = torch.LongTensor([1,2]) #롱 텐서에 대해서는 처리못함.\n",
    "try:\n",
    "    print(t.mean())\n",
    "except Exception as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "print(t.mean(dim = 0)) #(2,2)->(1,2)로 평균을 낸다.열끼리 평균 냄(1열평균, 2열평균)\n",
    "print(t.mean(dim = 1)) #(2,2)->(2,1)로 평균을 낸다.행끼리 평균 냄(1행평균, 2행평균)\n",
    "print(t.mean(dim = -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "#sum\n",
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "\n",
    "print(t.sum()) #그냥 네 개의 값을 모두 더한 것\n",
    "print(t.sum(dim = 0)) #axis = 0으로 sum해라\n",
    "print(t.sum(dim = 1)) #axis = 1으로 sum해라\n",
    "print(t.sum(dim = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(4.)\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "Max:  tensor([3., 4.])\n",
      "Argmax: tensor([1, 1])\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "#max and argmax\n",
    "\n",
    "t = torch.FloatTensor([[1,2], [3,4]])\n",
    "print(t)\n",
    "print(t.max()) #4개 중에서 가장 큰 걸 찾아줘\n",
    "\n",
    "print(t.max(dim = 0)) #axis = 0을 기준으로 max한 값을 찾아라\n",
    "#결과가 value값과 max인 index값 두개로 나옴.\n",
    "print('Max: ', t.max(dim = 0)[0]) #위의 두 값 중 value값이 [0]\n",
    "print('Argmax:', t.max(dim = 0)[1]) #위의 두 값 중 index값이 [1]\n",
    "\n",
    "print(t.max(dim = 1)) #axis = 1을 기준으로 max한 값을 찾아라\n",
    "print(t.max(dim = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "torch.Size([4, 3])\n",
      "tensor([[[ 0.,  1.,  2.]],\n",
      "\n",
      "        [[ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "#view(numpy->reshape)\n",
    "t = np.array([[[0,1,2],\n",
    "              [3,4,5]],\n",
    "              \n",
    "              [[6,7,8],\n",
    "              [9,10,11]]])\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft.shape)\n",
    "\n",
    "print(ft.view([-1, 3])) #앞엔 모르겠고 뒤의 차원은 3개를 가질래.\n",
    "print(ft.view([-1, 3]).shape) #그렇게 바꾸고 나니까 나온 shape\n",
    "\n",
    "print(ft.view([-1, 1, 3]))\n",
    "print(ft.view([-1, 1, 3]).shape) #결국 다 12개의 element가 들어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n",
      "tensor([0., 1., 2.])\n",
      "torch.Size([3])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "tensor([0., 1., 2.])\n"
     ]
    }
   ],
   "source": [
    "#squeeze(쥐어짜다.)\n",
    "#자동으로 원하는 dim이 1인 경우를 없어준다. \n",
    "ft = torch.FloatTensor([[0], [1], [2]])\n",
    "print(ft)\n",
    "print(ft.shape) #(3,1)의 1인 dimension은 squeeze를 이용하면 날라간다.\n",
    "print(ft.squeeze())\n",
    "print(ft.squeeze().shape)\n",
    "\n",
    "print(ft.squeeze(dim = 0)) #0번째 dimension은 3임, 따라서 그대로 나옴\n",
    "print(ft.squeeze(dim = 1)) #1번째 dimension은 1임, 따라서 squeeze된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([[0., 1., 2.]])\n",
      "torch.Size([1, 3])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n",
      "tensor([[0., 1., 2.]])\n",
      "torch.Size([1, 3])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "#unsqueeze (내가 원하는 dimension에 1을 넣어준다.)\n",
    "#여기서는 dimension을 꼭 명시해주어야 함!\n",
    "ft = torch.Tensor([0,1,2]) #(3,)\n",
    "print(ft.shape)\n",
    "\n",
    "print(ft.unsqueeze(dim = 0)) #dimension을 꼭 넣어줘야 함. (1,3)\n",
    "print(ft.unsqueeze(0).shape) #dimension 0에 1을 넣어줘라.\n",
    "\n",
    "print(ft.unsqueeze(dim = 1)) #dim 1에 1을 넣어줘라.\n",
    "print(ft.unsqueeze(1).shape) #(3,1)\n",
    "\n",
    "print(ft.view(1, -1)) #view는 reshape와 같았음.\n",
    "print(ft.view(1, -1).shape)\n",
    "\n",
    "print(ft.unsqueeze(-1)) #dimension = -1: 마지막 dimension -> dimension 1\n",
    "print(ft.unsqueeze(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([1., 2., 3., 4.])\n",
      "tensor([1, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([1., 0., 0., 1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nbt = (lt == 3)이라면\\nbt = (0,0,1,0)일 것이다.\\n왜냐하면 lt가 3인 경우만 참이므로 2번 인덱스만 1이고 나머지는 0\\nbt는 boolean 값을 저장\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type casting -> tensor의 타입을 바꿔주겠다.\n",
    "lt = torch.LongTensor([1,2,3,4])\n",
    "print(lt)\n",
    "\n",
    "print(lt.float())\n",
    "\n",
    "bt = torch.ByteTensor([True, False, False, True]) #boolean값을 저장\n",
    "print(bt)\n",
    "\n",
    "print(bt.long())\n",
    "print(bt.float())\n",
    "'''\n",
    "bt = (lt == 3)이라면\n",
    "bt = (0,0,1,0)일 것이다.\n",
    "왜냐하면 lt가 3인 경우만 참이므로 2번 인덱스만 1이고 나머지는 0\n",
    "bt는 boolean 값을 저장\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "#concatenate (이어붙이는것)\n",
    "x = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "y = torch.FloatTensor([[5, 6], [7, 8]])\n",
    "\n",
    "print(torch.cat([x, y], dim = 0)) #아래로 이어붙임\n",
    "print(torch.cat([x, y], dim = 1)) #옆으로 이어붙임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "#stacking -> concatenation을 좀더 다루기 쉽게\n",
    "x = torch.FloatTensor([1,4]) #dimension ->(2,)\n",
    "y = torch.FloatTensor([2,5])\n",
    "z = torch.FloatTensor([3,6])\n",
    "\n",
    "print(torch.stack([x, y, z])) #리스트 내에는 텐서가 들어있음. 쌓아라!\n",
    "#dimension -> (3,2) \n",
    "print(torch.stack([x, y, z], dim = 1)) #옆으로 쌓아라!\n",
    "#dimension -> (2, 3)\n",
    "\n",
    "print(torch.cat([x.unsqueeze(0), y.unsqueeze(0), z.unsqueeze(0)], dim = 0))\n",
    "#unsqueeze를 하면 (1,2)가 되고 그다음 cat하면 똑같은 결과가 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [2., 1., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#ones and zeros\n",
    "x = torch.FloatTensor([[0, 1, 2], [2, 1, 0]])\n",
    "print(x)\n",
    "\n",
    "print(torch.ones_like(x)) #x와 똑같은 shape로 1로 채워라\n",
    "print(torch.zeros_like(x)) #x와 똑같은 shape로 0로 채워라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "#inplace operation\n",
    "x = torch.FloatTensor([[1,2], [3,4]])\n",
    "print(x.mul(2.))\n",
    "print(x)\n",
    "print(x.mul_(2.)) #결과값이 x에 들어감\n",
    "print(x) #다시 프린트했을 때 x값이 들어가졌음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
